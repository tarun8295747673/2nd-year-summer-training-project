{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6QHvU2dfpFz"
   },
   "source": [
    "# üî•Fire Classification using Deep Convolutional Neural Networks and Transfer Learning\n",
    "\n",
    "<center><img src='https://media4.giphy.com/media/QKUx6kHItu3ilaVMdn/200.webp?cid=ecf05e47gics2m4k7lfvntuuwai9q63i175fusn61o163gvy&rid=200.webp&ct=s' height=300px width=300px></center>\n",
    "\n",
    "## üî¨Overview \n",
    "In the advancements of Artificial Intelligence(AI) and further development of sophisticated deep learning models, it is important for us to develop Computer Vision algorithms that could classify different domain of objects. In this case, fire image classification can be beneficial especially in use-cases like emergencies or disasters.\n",
    "\n",
    "\n",
    "## ‚ùóAuthor's Note:\n",
    "Make sure to run the cells from top to bottom with a GPU accelerator. There are some linux commands present in some cells so this is important to take into account. Also, any suggestions, comments and recommendations to improve the notebook will be highly appreciated. Cheers!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQELj5Dwf3on"
   },
   "source": [
    "# üèóÔ∏èImport Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lEzJXgjDf5y8"
   },
   "outputs": [],
   "source": [
    "# Import Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# Tensorflow Libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,models\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Model\n",
    "#from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# System libraries\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_SnZPRah_9D"
   },
   "source": [
    "# ü§ôCreate helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "F8ReVC2MiBRZ",
    "outputId": "c53e6082-d883-478d-d42f-887eb8399678"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Import series of helper functions for our notebook\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'helper_functions'"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "\n",
    "# Import series of helper functions for our notebook\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb_XPhOwiCNY"
   },
   "source": [
    "# üì•Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nD56d7Xxmc3"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (320, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kXkjadNxsNI",
    "outputId": "478c212a-b21e-4e08-e472-9b101759173e"
   },
   "outputs": [],
   "source": [
    "# Walk through each directory\n",
    "dataset = \"../input/fire-dataset/fire_dataset\"\n",
    "walk_through_dir(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLAnhGlf1hmo"
   },
   "source": [
    "# üìÖPlacing data into a Dataframe\n",
    "The first column `filepaths` contains the file path location of each individual images. The second column `labels`, on the other hand, contains the class label of the corresponding image from the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s14XOEp01m_s"
   },
   "outputs": [],
   "source": [
    "image_dir = Path(dataset)\n",
    "\n",
    "# Get filepaths and labels\n",
    "filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png'))\n",
    "\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "# Concatenate filepaths and labels\n",
    "image_df = pd.concat([filepaths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(image_dir.glob(r'**/*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3-uoP4n1oqK",
    "outputId": "4af0c4a5-c87d-42eb-aa1b-fe89f1fe8876"
   },
   "outputs": [],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agb1QMDO1pps"
   },
   "source": [
    "# üî≠Visualizing images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4WJVJ7j1rU9",
    "outputId": "777f0f9a-e46c-4475-ca6a-97a4e6fb89a3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "# Display 16 picture of the dataset with their labels\n",
    "random_index = np.random.randint(0, len(image_df), 16)\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image = Image.open(image_df.Filepath[random_index[i]])\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(image_df.Label[random_index[i]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwC4EWei1s-V"
   },
   "source": [
    "# üìùData Preprocessing\n",
    "The data will be split into three different categories: Training, Validation and Testing. The training data will be used to train the deep learning CNN model and its parameters will be fine tuned with the validation data. Finally, the performance of the data will be evaluated using the test data(data the model has not previously seen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaJlHTlz2K4M"
   },
   "outputs": [],
   "source": [
    "# Separate in train and test data\n",
    "train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3puUVDwl2Mcz"
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsftNShQ2PaK",
    "outputId": "ee3c99b5-3932-4187-f600-1e86cf334026"
   },
   "outputs": [],
   "source": [
    "# Split the data into three categories.\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLbR4WtD2RPg"
   },
   "outputs": [],
   "source": [
    "# Resize Layer\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(224,224),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSEhK2w02Uk-"
   },
   "source": [
    "# ü§πTraining the model\n",
    "The model images will be subjected to a pre-trained CNN model called MobileNetV2. Three callbacks will be utilized to monitor the training. These are: Model Checkpoint, Early Stopping, Tensorboard callback. The summary of the model hyperparameter is shown as follows:\n",
    "\n",
    "**Batch size** : 32\n",
    "\n",
    "**Epochs** : 100\n",
    "\n",
    "**Input Shape** : (320, 320, 3)\n",
    "\n",
    "**Output layer** : 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4VI_UxV2Wp2"
   },
   "outputs": [],
   "source": [
    "# Load the pretained model\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xn6j_La2Y2u"
   },
   "outputs": [],
   "source": [
    "# Create checkpoint callback\n",
    "checkpoint_path = \"fires_classification_model_checkpoint\"\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_path,\n",
    "                                      save_weights_only=True,\n",
    "                                      monitor=\"val_accuracy\",\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YbP7g6Xh2abB"
   },
   "outputs": [],
   "source": [
    "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
    "early_stopping = EarlyStopping(monitor = \"val_loss\", # watch the val loss metric\n",
    "                               patience = 5,\n",
    "                               restore_best_weights = True) # if val loss decreases for 3 epochs in a row, stop training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alynENS02jm4"
   },
   "source": [
    "# üöÑTraining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkcAsl5H2tYl",
    "outputId": "173d8e87-7f30-401e-fe3b-077c21025b59"
   },
   "outputs": [],
   "source": [
    "inputs = pretrained_model.input\n",
    "x = resize_and_rescale(inputs)\n",
    "\n",
    "x = Dense(256, activation='relu')(pretrained_model.output)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    steps_per_epoch=len(train_images),\n",
    "    validation_data=val_images,\n",
    "    validation_steps=len(val_images),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        early_stopping,\n",
    "        create_tensorboard_callback(\"training_logs\", \n",
    "                                    \"fire_classification\"),\n",
    "        checkpoint_callback,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BWrofxS2vO0"
   },
   "source": [
    "# ‚úîÔ∏èModel Evaluation\n",
    "The test dataset will be used to evaluate the performance of the model.One of the metrics that will be tested would be accuracy which measures the fraction of predictions the model got right. Other metrics are as follows:\n",
    "\n",
    "**Precision(P)**: \n",
    "The fraction of true positives (TP, correct predictions) from the total amount of relevant results, i.e., the sum of TP and false positives (FP). For multi-class classification problems, P is averaged among the classes. The following is the formula for precision.\n",
    "\n",
    "<center>$P=TP/(TP+FP)$</center>\n",
    "\n",
    "**Recall(R)**: \n",
    "The fraction of TP from the total amount of TP and false negatives (FN). For multi-class classification problems, R gets averaged among all the classes. The following is the formula for recall.\n",
    "<center>$R=TP/(TP+FN)$</center>\n",
    "\n",
    "**F1 score(F1)**: \n",
    "The harmonic mean of precision and recall. For multi-class classification problems, F1 gets averaged among all the classes. The following is the formula for F1 score.\n",
    "<center>$F1=2 * (TP * FP)/(TP+FP)$</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CS-g90hJ340B",
    "outputId": "8b35403d-9dc0-4a65-b08e-ce223aef2bdb"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, verbose=0)\n",
    "\n",
    "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5oGHvsG368q"
   },
   "source": [
    "# üìâVisualizing loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01SS6RVx38o7",
    "outputId": "f982ac64-9de4-4306-c917-1b7a1d0f6e06"
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BL7xgPz4Fv-"
   },
   "source": [
    "# üîÆMaking predictions on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxAegJBB4HlW",
    "outputId": "c836256c-be8e-4346-b6c2-d4c39d030db4"
   },
   "outputs": [],
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(test_images)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Map the label\n",
    "labels = (train_images.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred = [labels[k] for k in pred]\n",
    "\n",
    "# Display the result\n",
    "print(f'The first 5 predictions: {pred[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWO4e4wb4Iln",
    "outputId": "a58f3382-f991-43ac-e54f-6bd9a36dd25f"
   },
   "outputs": [],
   "source": [
    "  # Display 25 random pictures from the dataset with their labels\n",
    "random_index = np.random.randint(0, len(test_df) - 1, 15)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image = Image.open(test_df.Filepath.iloc[random_index[i]])\n",
    "    ax.imshow(image)\n",
    "    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:\n",
    "      color = \"green\"\n",
    "    else:\n",
    "      color = \"red\"\n",
    "    ax.set_title(f\"True: {test_df.Label.iloc[random_index[i]]}\\nPredicted: {pred[random_index[i]]}\", color=color)\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLYd5vYJ4KTu"
   },
   "source": [
    "# üìäPlotting the Classification Reports and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ySAZoU74MlB",
    "outputId": "b4c6bf97-d4b1-4def-d1a8-bb79c9685504"
   },
   "outputs": [],
   "source": [
    "y_test = list(test_df.Label)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYWvkbXI4Ns2",
    "outputId": "7e04d8a2-3263-4a31-d469-70d8140cb167"
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_test, pred, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QS8khAfS4Oy3"
   },
   "outputs": [],
   "source": [
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(15, 7), text_size=10, norm=False, savefig=False): \n",
    "    \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
    "\n",
    "    If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
    "  will be used.\n",
    "\n",
    "  Args:\n",
    "    y_true: Array of truth labels (must be same shape as y_pred).\n",
    "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
    "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
    "    figsize: Size of output figure (default=(10, 10)).\n",
    "    text_size: Size of output figure text (default=15).\n",
    "    norm: normalize values or not (default=False).\n",
    "    savefig: save confusion matrix to file (default=False).\n",
    "  \n",
    "  Returns:\n",
    "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
    "\n",
    "  Example usage:\n",
    "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
    "                          y_pred=y_preds, # predicted labels\n",
    "                          classes=class_names, # array of class label names\n",
    "                          figsize=(15, 15),\n",
    "                          text_size=10)\n",
    "    \"\"\"  \n",
    "  # Create the confustion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
    "    n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
    "\n",
    "    # Plot the figure and make it pretty\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Are there a list of classes?\n",
    "    if classes:\n",
    "        labels = classes\n",
    "    else:\n",
    "        labels = np.arange(cm.shape[0])\n",
    "  \n",
    "    # Label the axes\n",
    "    ax.set(title=\"Confusion Matrix\",\n",
    "         xlabel=\"Predicted label\",\n",
    "         ylabel=\"True label\",\n",
    "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
    "         yticks=np.arange(n_classes), \n",
    "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
    "         yticklabels=labels)\n",
    "  \n",
    "    # Make x-axis labels appear on bottom\n",
    "    ax.xaxis.set_label_position(\"bottom\")\n",
    "    ax.xaxis.tick_bottom()\n",
    "    ### Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n",
    "    plt.xticks(rotation=90, fontsize=text_size)\n",
    "    plt.yticks(fontsize=text_size)\n",
    "\n",
    "    # Set the threshold for different colors\n",
    "    threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "    # Plot the text on each cell\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if norm:\n",
    "            plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                size=text_size)\n",
    "        else:\n",
    "            plt.text(j, i, f\"{cm[i, j]}\",\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "              size=text_size)\n",
    "\n",
    "  # Save the figure to the current working directory\n",
    "    if savefig:\n",
    "        fig.savefig(\"confusion_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMsUQM6n4Pyx",
    "outputId": "3eb72904-123b-4e7b-d5b6-e3e339fab375"
   },
   "outputs": [],
   "source": [
    "make_confusion_matrix(y_test, pred, list(labels.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGvdcGEI4RCb"
   },
   "source": [
    "### Thanks for viewing the notebook. I would greatly appreciate any feedback, suggestions and recommendations for improvement. Cheers! \n",
    "\n",
    "<center><img src='https://media4.giphy.com/media/M9gbBd9nbDrOTu1Mqx/giphy.gif?cid=790b7611704aa2ca4e403287801480a6c753abf45f3e6242&rid=giphy.gif&ct=s' \n",
    "     height=30px width=160px /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 529007,
     "sourceId": 969357,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30235,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
